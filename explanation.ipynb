{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Soccer Football Object Detection Project Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the explanation of the image processing and deep learning techniques used in this object detection project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from collections import Counter\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import Image\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "yolo = YOLO(\"yolov8x\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!yolo task=detect mode=predict model=yolov8n.pt source=media/image.png project=./runs conf=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"runs/predict/image.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the players are detected however the ball is not, we will fix this later on.\n",
    "For now we can label the players with their corresponding class (team color) using the average color of each player box.\n",
    "\n",
    "Let's plot each mean color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = cv2.imread(\"media/image.png\")\n",
    "results = yolo(frame, classes = [0,32], conf = .5 )\n",
    "for result in results:\n",
    "    boxes = result.boxes\n",
    "    for box in boxes:\n",
    "\n",
    "        # convert box attributes from tensor to arrays\n",
    "        coords = box.xyxy.cpu().numpy()[0].astype(int)\n",
    "        class_id = int(box.cls.cpu().numpy()[0])\n",
    "        confidence = box.conf.cpu().numpy()[0]\n",
    "        \n",
    "        x1, y1, x2, y2 = coords\n",
    "        \n",
    "        # crop the frame with box coords\n",
    "        crop_frame = frame[y1:y2, x1:x2]\n",
    "\n",
    "    \n",
    "        mean_color = np.mean(crop_frame, axis=(0,1)).astype(int)\n",
    "\n",
    "        cv2.rectangle(frame, \n",
    "                            (x1, y1), \n",
    "                            (x2, y2), \n",
    "                            (int(mean_color[0]), int(mean_color[1]), int(mean_color[2])), \n",
    "                            10)\n",
    "\n",
    "        label = f\"{'Person' if class_id == 0 else 'Ball'}: {confidence:.2f}\"\n",
    "        color_text = f\"RGB: {mean_color[0]},{mean_color[1]},{mean_color[2]}\"\n",
    "        cv2.putText(frame, \n",
    "                    label, \n",
    "                    (x1, y1 - 25), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                    0.5, \n",
    "                    (255, 255, 255), \n",
    "                    2)\n",
    "        cv2.putText(frame, \n",
    "                    color_text, \n",
    "                    (x1, y1 - 10), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                    0.4, \n",
    "                    (255, 255, 255), \n",
    "                    1)\n",
    "plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen, the floor color is interfering so we will center each box to detect only the T-shirts mean color.\n",
    " \n",
    "\n",
    "Additionally we will assign each mean color to the nearest extreme color detected, using color distances techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_distance(color1, color2):\n",
    "    \"\"\"Calculate Euclidean distance between two colors\"\"\"\n",
    "    return np.sqrt(np.sum((color1 - color2) ** 2))\n",
    "\n",
    "def assign_team(color, team_colors):\n",
    "    \"\"\"Assign a color to the closest team based on color distance\"\"\"\n",
    "    if not team_colors.any():\n",
    "        return 0\n",
    "    distances = [color_distance(color, team_color) for team_color in team_colors]\n",
    "    return np.argmin(distances)\n",
    "\n",
    "    \n",
    "def preprocess_frame(frame):\n",
    "    # Convert to HSV color space\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Apply CLAHE for contrast enhancement\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    h, s, v = cv2.split(hsv)  # Unpack directly into variables\n",
    "    v = clahe.apply(v)  # Apply CLAHE to V channel\n",
    "    hsv = cv2.merge([h, s, v])  # Merge back\n",
    "    \n",
    "    \n",
    "    # Convert back to BGR and enhance edges\n",
    "    processed = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "    # Sharpen the image\n",
    "    kernel_sharpen = np.array([[-1,-1,-1],\n",
    "                              [-1, 9,-1],\n",
    "                              [-1,-1,-1]])\n",
    "    processed_frame = cv2.filter2D(processed, -1, kernel_sharpen)\n",
    "\n",
    "    return processed_frame\n",
    "def process_detections(frame, results):\n",
    "        \n",
    "        player_colors = []   \n",
    "        player_boxes = []     \n",
    "\n",
    "        \n",
    "        processed_frame = preprocess_frame(frame)\n",
    "\n",
    "        for result in results:\n",
    "            boxes = result.boxes\n",
    "            for box in boxes:\n",
    "                if len(box.xyxy) >= 1:\n",
    "\n",
    "                    class_id = int(box.cls.cpu().numpy()[0])\n",
    "\n",
    "                    if class_id == 0:\n",
    "                        x1, y1, x2, y2 = box.xyxy.cpu().numpy()[0].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "                        # centering the box\n",
    "                        mid_x = (x1 + x2) // 2\n",
    "                        mid_y = (y1 + y2) // 2\n",
    "                        half_height = (y2 - y1) // 2\n",
    "                        half_width = (x2 - x1) // 2\n",
    "                        centered_x1 = max(x1, mid_x - half_width // 2)\n",
    "                        centered_x2 = min(x2, mid_x + half_width // 2)\n",
    "                        centered_y1 = max(y1, mid_y - half_height // 2)\n",
    "                        centered_y2 = min(y2, mid_y + half_height // 2)\n",
    "\n",
    "                        crop_frame = processed_frame[centered_y1:centered_y2, centered_x1:centered_x2]\n",
    "                        mean_color = np.mean(crop_frame, axis=(0,1)).astype(int)\n",
    "                        \n",
    "                        \n",
    "                        player_colors.append(mean_color)\n",
    "\n",
    "                        player_boxes.append({\n",
    "                        'coords': (centered_x1, centered_y1, centered_x2, centered_y2),\n",
    "                        'color': mean_color,\n",
    "                        })\n",
    "\n",
    "                        \n",
    "                        \n",
    "                        color_text = f\"RGB: {mean_color[0]},{mean_color[1]},{mean_color[2]}\"\n",
    "\n",
    "                        cv2.putText(frame, \n",
    "                            color_text, \n",
    "                            (x1, y1 - 10), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                            0.4, \n",
    "                            (255, 255, 255), \n",
    "                            1)\n",
    "                                \n",
    "        # Use K-means to find team colors\n",
    "\n",
    "        if len(player_colors) >= 2:\n",
    "            kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "            kmeans.fit(player_colors)\n",
    "            team_colors = kmeans.cluster_centers_\n",
    "        \n",
    "            # Second pass: draw boxes with team colors\n",
    "            for player in player_boxes:\n",
    "                team = assign_team(player['color'], team_colors)\n",
    "                x1, y1, x2, y2 = player['coords']                \n",
    "                # Add team label\n",
    "                label = f\"Team {team+1}\"\n",
    "                \n",
    "                team_color = team_colors[team]\n",
    "                if team == 0:\n",
    "                    cv2.rectangle(frame, \n",
    "                                (x1, y1), \n",
    "                                (x2, y2), \n",
    "                                (30,144,255), \n",
    "                                2)\n",
    "                elif team == 1:\n",
    "                    cv2.rectangle(frame, \n",
    "                                (x1, y1), \n",
    "                                (x2, y2), \n",
    "                                (255,0,0), \n",
    "                                2)\n",
    "                cv2.putText(frame, \n",
    "                            label, \n",
    "                            (x1, y1 - 45), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                            0.5, \n",
    "                            (255, 255, 255), \n",
    "                            2)\n",
    "        return frame, processed_frame\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "def display_detections(path, frame_skip, frames):\n",
    "    is_image=False\n",
    "    if path == 0:\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        output_dir = \"outputs/webcam\"\n",
    "    else:\n",
    "        file_ext = Path(path).suffix.lower()\n",
    "\n",
    "        if file_ext in [\".jpg\", \".jpeg\", \".png\"]:\n",
    "            is_image = True\n",
    "        else:\n",
    "            cap = cv2.VideoCapture(path)\n",
    "            \n",
    "        output_dir = f\"outputs/{Path(path).stem}\"\n",
    "\n",
    "\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir) \n",
    "    else:\n",
    "        n = 1\n",
    "        while True:\n",
    "            new_dir = f\"{output_dir}_{n}\"\n",
    "            if not os.path.exists(new_dir):\n",
    "                os.makedirs(new_dir)\n",
    "                break\n",
    "            n += 1\n",
    "        output_dir= new_dir\n",
    "\n",
    "    n_frames = 0\n",
    "    \n",
    "    if is_image:\n",
    "        frame = cv2.imread(path)\n",
    "        if frame is not None:\n",
    "            frame, processed_frame = process_detections(frame, yolo(frame, classes=[0, 32], conf=0.5))\n",
    "            cv2.imwrite(f\"{output_dir}/image_original.png\", frame)\n",
    "            cv2.imwrite(f\"{output_dir}/image_preprocessed.png\", processed_frame)\n",
    "            print(f\"Results saved in {output_dir}\")\n",
    "        else:\n",
    "            print(\"Error: Could not read the image file.\")\n",
    "    else:\n",
    "        while cap.isOpened() and n_frames < frames:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break  \n",
    "\n",
    "            frame, processed_frame = process_detections(frame, yolo(frame, classes=[0, 32], conf=0.5))\n",
    "            \n",
    "            cv2.imwrite(f\"{output_dir}/frame{n_frames}_original.png\", frame)\n",
    "            cv2.imwrite(f\"{output_dir}/frame{n_frames}_preprocessed.png\", processed_frame)\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "            n_frames += 1\n",
    "\n",
    "            for _ in range(frame_skip):\n",
    "                if n_frames >= frames:\n",
    "                    break\n",
    "                cap.read()  \n",
    "                n_frames += 1  \n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(f\"Results saved in {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 11 persons, 162.8ms\n",
      "Speed: 15.1ms preprocess, 162.8ms inference, 555.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 69.4ms\n",
      "Speed: 2.0ms preprocess, 69.4ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved in outputs/o\n"
     ]
    }
   ],
   "source": [
    "display_detections(\"videos/o.mp4\", 0, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
