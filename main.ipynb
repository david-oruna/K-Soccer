{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from collections import Counter\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "yolo = YOLO(\"yolov8n.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.7 ðŸš€ Python-3.10.15 torch-2.4.1 CUDA:0 (NVIDIA GeForce GTX 1650, 4096MiB)\n",
      "YOLOv8n summary (fused): 168 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "\n",
      "image 1/1 c:\\Users\\DHO_d\\OneDrive\\Escritorio\\football_ieee\\football-analysis\\image.png: 384x640 91 persons, 1 sports ball, 1 skateboard, 1 chair, 46.9ms\n",
      "Speed: 0.0ms preprocess, 46.9ms inference, 152.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns\\predict\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict model=yolov8n.pt source=image.png project=./runs conf=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Users\\DHO_d\\OneDrive\\Escritorio\\football_ieee\\football-analysis\\image.png: 384x640 8 persons, 60.0ms\n",
      "Speed: 9.9ms preprocess, 60.0ms inference, 179.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
       " obb: None\n",
       " orig_img: array([[[ 42,  33,  31],\n",
       "         [ 42,  33,  31],\n",
       "         [ 42,  33,  31],\n",
       "         ...,\n",
       "         [ 42,  33,  31],\n",
       "         [ 42,  33,  31],\n",
       "         [ 42,  33,  31]],\n",
       " \n",
       "        [[ 42,  33,  31],\n",
       "         [ 42,  33,  31],\n",
       "         [ 42,  33,  31],\n",
       "         ...,\n",
       "         [ 42,  33,  31],\n",
       "         [ 42,  33,  31],\n",
       "         [ 42,  33,  31]],\n",
       " \n",
       "        [[ 42,  33,  31],\n",
       "         [ 42,  33,  31],\n",
       "         [ 42,  33,  31],\n",
       "         ...,\n",
       "         [ 42,  33,  31],\n",
       "         [ 42,  33,  31],\n",
       "         [ 42,  33,  31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[132, 104,  53],\n",
       "         [134, 105,  53],\n",
       "         [134, 105,  53],\n",
       "         ...,\n",
       "         [ 64,  69,  64],\n",
       "         [ 64,  69,  64],\n",
       "         [ 65,  69,  64]],\n",
       " \n",
       "        [[130, 102,  52],\n",
       "         [131, 103,  52],\n",
       "         [132, 103,  52],\n",
       "         ...,\n",
       "         [ 62,  67,  63],\n",
       "         [ 62,  67,  63],\n",
       "         [ 63,  67,  63]],\n",
       " \n",
       "        [[128, 101,  51],\n",
       "         [129, 102,  51],\n",
       "         [128, 100,  50],\n",
       "         ...,\n",
       "         [ 60,  64,  62],\n",
       "         [ 60,  64,  61],\n",
       "         [ 61,  65,  60]]], dtype=uint8)\n",
       " orig_shape: (670, 1152)\n",
       " path: 'c:\\\\Users\\\\DHO_d\\\\OneDrive\\\\Escritorio\\\\football_ieee\\\\football-analysis\\\\image.png'\n",
       " probs: None\n",
       " save_dir: 'c:\\\\Users\\\\DHO_d\\\\runs\\\\detect\\\\predict'\n",
       " speed: {'preprocess': 9.911775588989258, 'inference': 59.95464324951172, 'postprocess': 179.40831184387207}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imread(\"image.png\")\n",
    "result = yolo(\"image.png\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VideoProcessor:\n",
    "    def __init__(self, modelo='yolov8n.pt', source='camera', video_path=None, ruta_carpeta=None, save = False, n = 1,depurar = False):\n",
    "        self.yolo_model = YOLO(modelo)\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(f\"Using device: {self.device}\")\n",
    "        self.yolo_model.to(self.device)\n",
    "        \n",
    "        self.source = source\n",
    "        self.n = n\n",
    "        self.depurar = depurar\n",
    "        if source == 'camera':\n",
    "            self.cap = cv2.VideoCapture(0)  # 0 para la cÃ¡mara por defecto\n",
    "        elif source == 'video' and video_path:\n",
    "            self.cap = cv2.VideoCapture(video_path)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid source or missing video path\")\n",
    "        \n",
    "        if not self.cap.isOpened():\n",
    "            raise RuntimeError(f\"Error: Could not open {'camera' if source == 'camera' else 'video file'}.\")\n",
    "        else:\n",
    "            print(f\"{'Camera' if source == 'camera' else 'Video file'} opened successfully.\")\n",
    "        \n",
    "        # Precalcular colores para las detecciones\n",
    "        self.colors = np.random.randint(0, 255, size=(80, 3), dtype='uint8')\n",
    "        \n",
    "        self.ruta_carpeta = ruta_carpeta\n",
    "        if ruta_carpeta:\n",
    "            os.makedirs(self.ruta_carpeta, exist_ok=True)\n",
    "        self.save = save\n",
    "    def procesar(self, num_frames=None, frame_skip=0):\n",
    "        frames_leidos = 0\n",
    "        frames_procesados = 0\n",
    "        total_time = 0\n",
    "\n",
    "        while self.cap.isOpened():\n",
    "            if num_frames is not None and frames_procesados >= num_frames:\n",
    "                break\n",
    "\n",
    "            for _ in range(frame_skip + 1):\n",
    "                ret, frame = self.cap.read()\n",
    "                if not ret:\n",
    "                    print(\"Fin del video o error de lectura.\")\n",
    "                    return\n",
    "                frames_leidos += 1\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Factor de escala\n",
    "            self.n = 1\n",
    "            original_height, original_width = frame.shape[:2]\n",
    "            frame = cv2.resize(frame, (int(original_width * self.n), int(original_height * self.n)))\n",
    "\n",
    "            # Detectar solo personas con batch processing\n",
    "            results = self.yolo_model(frame, stream=True,classes = [0,32] ,conf=0.1)  # 0 es el Ã­ndice para 'person'\n",
    "\n",
    "            # Procesar resultados\n",
    "            for result in results:\n",
    "                detections = result.boxes\n",
    "                print(f\"Frame {frames_leidos} detecciones: {len(detections)}\")\n",
    "                frame_with_detections = self.process_detections(frame, detections)\n",
    "                \n",
    "                # Mostrar el frame con las detecciones\n",
    "                cv2.imshow('Detecciones', frame_with_detections)\n",
    "                if self.save == True:\n",
    "                    self.guardar_frame(frame_with_detections,frames_leidos)\n",
    "\n",
    "            end_time = time.time()\n",
    "            elapsed_time = end_time - start_time\n",
    "            total_time += elapsed_time\n",
    "\n",
    "            print(f\"Tiempo de procesamiento del frame {frames_leidos}: {elapsed_time:.4f} segundos\")\n",
    "\n",
    "            frames_procesados += 1\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        avg_time = total_time / frames_procesados if frames_procesados > 0 else 0\n",
    "        print(f\"Frames procesados: {frames_procesados}\")\n",
    "        print(f\"Tiempo promedio de procesamiento por frame: {avg_time:.4f} segundos\")\n",
    "        print(f\"FPS promedio: {1/avg_time:.2f}\")\n",
    "\n",
    "        self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"Captura de video liberada.\")\n",
    "        \n",
    "    def modify_frame(self, frame):\n",
    "        hsv_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "        # MÃ¡scara para colores azules\n",
    "        mask_blue = cv2.inRange(hsv_frame, np.array([75, 50, 50]), np.array([135, 255, 255]))\n",
    "        \n",
    "        # Suavizar y limpiar la mÃ¡scara (operaciones morfolÃ³gicas)\n",
    "        #kernel = np.ones((5, 5), np.uint8)\n",
    "        #mask_blue = cv2.GaussianBlur(mask_blue, (5, 5), 0)\n",
    "        #mask_blue = cv2.morphologyEx(mask_blue, cv2.MORPH_CLOSE, kernel)\n",
    "        #mask_blue = cv2.morphologyEx(mask_blue, cv2.MORPH_OPEN, kernel)\n",
    "        \n",
    "        # Reducir saturaciÃ³n en Ã¡reas azules\n",
    "        hsv_frame[:, :, 1] = np.where(mask_blue > 0, 0, hsv_frame[:, :, 1])\n",
    "        \n",
    "        # Ajustar HSV perfil rojo amarillo\n",
    "        hsv_frame[:, :, 0] = np.clip(hsv_frame[:, :, 0], 37, 179)\n",
    "        hsv_frame[:, :, 2] = 255  # Maximizar el valor (brillo)\n",
    "        #Ajustar HSV perfil blancos\n",
    "        #hsv_frame[:, :, 0] = np.clip(hsv_frame[:, :, 0], 29, 132)  # AsegÃºrate de que H no exceda los lÃ­mites\n",
    "        #hsv_frame[:, :, 2] = 255  # Maximizar el valor (brillo)\n",
    "\n",
    "        # ajustar vivos \n",
    "\n",
    "        H_low, H_high = 0, 179\n",
    "        S_low, S_high = 0, 255\n",
    "        V_low, V_high = 255, 255\n",
    "\n",
    "        # Aplicar los lÃ­mites a los canales H, S, y V\n",
    "        #hsv_frame[:, :, 0] = np.clip(hsv_frame[:, :, 0], H_low, H_high)  # Canal H\n",
    "        #hsv_frame[:, :, 1] = np.clip(hsv_frame[:, :, 1], S_low, S_high)  # Canal S\n",
    "        #hsv_frame[:, :, 2] = np.clip(hsv_frame[:, :, 2], V_low, V_high)  # Canal V\n",
    "        \n",
    "        return cv2.cvtColor(hsv_frame, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    def process_detections(self, frame, detections):\n",
    "        modified_frame = self.modify_frame(frame)\n",
    "        player_colors = []\n",
    "        \n",
    "        for detection in detections:\n",
    "            if len(detection.xyxy) >= 1:\n",
    "                x1, y1, x2, y2 = map(int, detection.xyxy[0][:4])\n",
    "                mid_x = (x1 + x2) // 2\n",
    "                mid_y = (y1 + y2) // 2\n",
    "                half_height = (y2 - y1) // 2\n",
    "                half_width = (x2 - x1) // 2\n",
    "                centered_x1 = max(x1, mid_x - half_width // 2)\n",
    "                centered_x2 = min(x2, mid_x + half_width // 2)\n",
    "                centered_y1 = max(y1, mid_y - half_height // 2)\n",
    "                centered_y2 = min(y2, mid_y + half_height // 2)\n",
    "\n",
    "                player_img = modified_frame[centered_y1:centered_y2, centered_x1:centered_x2]\n",
    "                avg_color_hsv = cv2.cvtColor(np.uint8([[player_img.mean(axis=(0,1))]]), cv2.COLOR_BGR2HSV)[0][0]\n",
    "                player_colors.append(tuple(avg_color_hsv.astype(int)))\n",
    "        \n",
    "        team_colors = self.get_team_colors(player_colors)\n",
    "        if self.depurar == False:\n",
    "            frame_with_detections = self.draw_detections(frame.copy(), detections, team_colors)\n",
    "        else:\n",
    "            frame_with_detections = self.draw_detections(modified_frame, detections, team_colors)\n",
    "        # Mostrar el frame con las detecciones\n",
    "        cv2.imshow('Detecciones', frame_with_detections)\n",
    "        \n",
    "        return frame_with_detections\n",
    "\n",
    "    def get_team_colors(self, player_colors):\n",
    "        color_counts = Counter(player_colors)\n",
    "        unique_colors = list(color_counts.keys())\n",
    "        \n",
    "        if len(unique_colors) < 2:\n",
    "            return None\n",
    "        \n",
    "        distances = np.linalg.norm(np.array(unique_colors)[:, np.newaxis] - np.array(unique_colors), axis=2)\n",
    "        i, j = np.unravel_index(distances.argmax(), distances.shape)\n",
    "        \n",
    "        return tuple(sorted([unique_colors[i], unique_colors[j]]))\n",
    "\n",
    "    def draw_detections(self, frame, detections, team_colors):\n",
    "        for detection in detections:\n",
    "            if len(detection.xyxy) >= 1:\n",
    "                x1, y1, x2, y2 = map(int, detection.xyxy[0][:4])\n",
    "                mid_x = (x1 + x2) // 2\n",
    "                mid_y = (y1 + y2) // 2\n",
    "                half_height = (y2 - y1) // 2\n",
    "                half_width = (x2 - x1) // 2\n",
    "                centered_x1 = max(x1, mid_x - half_width // 2)\n",
    "                centered_x2 = min(x2, mid_x + half_width // 2)\n",
    "                centered_y1 = max(y1, mid_y - half_height // 2)\n",
    "                centered_y2 = min(y2, mid_y + half_height // 2)\n",
    "                \n",
    "                player_img = frame[centered_y1:centered_y2, centered_x1:centered_x2]\n",
    "                avg_color_hsv = cv2.cvtColor(np.uint8([[player_img.mean(axis=(0,1))]]), cv2.COLOR_BGR2HSV)[0][0]\n",
    "                \n",
    "                team = 1 if team_colors and np.linalg.norm(avg_color_hsv - team_colors[0]) < np.linalg.norm(avg_color_hsv - team_colors[1]) else 2\n",
    "                \n",
    "                cv2.rectangle(frame, (centered_x1, centered_y1), (centered_x2, centered_y2), cv2.cvtColor(np.uint8([[avg_color_hsv]]), cv2.COLOR_HSV2BGR)[0][0].tolist(), 1)\n",
    "                cv2.circle(frame, ((x1+x2)//2, (y1+y2)//2), 3, cv2.cvtColor(np.uint8([[avg_color_hsv]]), cv2.COLOR_HSV2BGR)[0][0].tolist(), -1)\n",
    "                cv2.putText(frame, f'Equipo {team}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
    "        \n",
    "        return frame\n",
    "\n",
    "\n",
    "    def guardar_frame(self, frame, frame_index):\n",
    "            if self.ruta_carpeta is None:\n",
    "                print(\"No se ha especificado una carpeta para guardar los frames.\")\n",
    "                return\n",
    "            try:\n",
    "                os.makedirs(self.ruta_carpeta, exist_ok=True)\n",
    "                output_frame_filename = f\"frame_clasificado_{frame_index}.png\"\n",
    "                saved_path = os.path.join(self.ruta_carpeta, output_frame_filename)\n",
    "                cv2.imwrite(saved_path, frame)\n",
    "                if os.path.exists(saved_path):\n",
    "                    print(f'Imagen del frame guardada como {output_frame_filename}')\n",
    "                else:\n",
    "                    print(f'Error al guardar la imagen del frame {frame_index}.')\n",
    "            except Exception as e:\n",
    "                print(f\"Error al guardar el frame {frame_index}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def modify_frame(frame):\n",
    "    frame = cv2.imread(frame)\n",
    "    hsv_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Lower all colors by reducing the saturation and value\n",
    "    hsv_frame[:, :, 1] = hsv_frame[:, :, 1] * 0.5  # Reduce saturation by 50%\n",
    "    hsv_frame[:, :, 2] = hsv_frame[:, :, 2] * 0.5  # Reduce value (brightness) by 50%\n",
    "    \n",
    "    # Intensify yellow\n",
    "    mask_yellow = cv2.inRange(hsv_frame, np.array([20, 50, 50]), np.array([30, 255, 255]))\n",
    "    hsv_frame[:, :, 1] = np.where(mask_yellow > 0, hsv_frame[:, :, 1] * 2, hsv_frame[:, :, 1])  # Increase saturation for yellow\n",
    "    hsv_frame[:, :, 2] = np.where(mask_yellow > 0, hsv_frame[:, :, 2] * 2, hsv_frame[:, :, 2])  # Increase value for yellow\n",
    "    \n",
    "    return cv2.cvtColor(hsv_frame, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "frame = modify_frame(\"image.png\")\n",
    "# save frame\n",
    "cv2.imwrite(\"x/image.png\", frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = VideoProcessor(modelo='yolov8n.pt', source='camera', n = 1, save = True, ruta_carpeta='pruebavivo5',depurar=True)\n",
    "processor.procesar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Video file opened successfully.\n",
      "\n",
      "0: 640x384 14 persons, 10.0ms\n",
      "Frame 101 detecciones: 14\n",
      "Imagen del frame guardada como frame_clasificado_101.png\n",
      "Speed: 10.2ms preprocess, 10.0ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Tiempo de procesamiento del frame 101: 0.3098 segundos\n",
      "\n",
      "0: 640x384 7 persons, 13.5ms\n",
      "Frame 202 detecciones: 7\n",
      "Imagen del frame guardada como frame_clasificado_202.png\n",
      "Speed: 0.0ms preprocess, 13.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Tiempo de procesamiento del frame 202: 0.0850 segundos\n",
      "\n",
      "0: 640x384 4 persons, 10.1ms\n",
      "Frame 303 detecciones: 4\n",
      "Imagen del frame guardada como frame_clasificado_303.png\n",
      "Speed: 0.0ms preprocess, 10.1ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Tiempo de procesamiento del frame 303: 0.0801 segundos\n",
      "\n",
      "0: 640x384 2 persons, 1 sports ball, 11.0ms\n",
      "Frame 404 detecciones: 3\n",
      "Imagen del frame guardada como frame_clasificado_404.png\n",
      "Speed: 0.0ms preprocess, 11.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Tiempo de procesamiento del frame 404: 0.0561 segundos\n",
      "\n",
      "0: 640x384 13 persons, 1.9ms\n",
      "Frame 505 detecciones: 13\n",
      "Imagen del frame guardada como frame_clasificado_505.png\n",
      "Speed: 1.5ms preprocess, 1.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Tiempo de procesamiento del frame 505: 0.0679 segundos\n",
      "\n",
      "0: 640x384 8 persons, 11.6ms\n",
      "Frame 606 detecciones: 8\n",
      "Imagen del frame guardada como frame_clasificado_606.png\n",
      "Speed: 1.9ms preprocess, 11.6ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Tiempo de procesamiento del frame 606: 0.0738 segundos\n",
      "\n",
      "0: 640x384 9 persons, 40.7ms\n",
      "Frame 707 detecciones: 9\n",
      "Imagen del frame guardada como frame_clasificado_707.png\n",
      "Speed: 0.0ms preprocess, 40.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Tiempo de procesamiento del frame 707: 0.1081 segundos\n",
      "\n",
      "0: 640x384 12 persons, 26.2ms\n",
      "Frame 808 detecciones: 12\n",
      "Imagen del frame guardada como frame_clasificado_808.png\n",
      "Speed: 9.4ms preprocess, 26.2ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Tiempo de procesamiento del frame 808: 0.0980 segundos\n",
      "\n",
      "0: 640x384 6 persons, 79.6ms\n",
      "Frame 909 detecciones: 6\n",
      "Imagen del frame guardada como frame_clasificado_909.png\n",
      "Speed: 4.0ms preprocess, 79.6ms inference, 15.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Tiempo de procesamiento del frame 909: 0.1604 segundos\n",
      "\n",
      "0: 640x384 7 persons, 90.0ms\n",
      "Frame 1010 detecciones: 7\n",
      "Imagen del frame guardada como frame_clasificado_1010.png\n",
      "Speed: 9.5ms preprocess, 90.0ms inference, 9.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Tiempo de procesamiento del frame 1010: 0.1721 segundos\n",
      "Frames procesados: 10\n",
      "Tiempo promedio de procesamiento por frame: 0.1211 segundos\n",
      "FPS promedio: 8.26\n",
      "Captura de video liberada.\n"
     ]
    }
   ],
   "source": [
    "processor = VideoProcessor(modelo='yolov8n.pt', source='video', video_path='s.mp4',ruta_carpeta = 'vivo2',save = True,n = 1,depurar=False)\n",
    "processor.procesar(num_frames=10, frame_skip=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
